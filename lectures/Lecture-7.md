---
layout: default
title: "Lecture 7: Train, Evaluate, and Integrate Machine Learning Models (part 2)"
has_children: false
# parent: "Lectures"
nav_order: 7
nav_exclude: false
---

# Lecture 7: Train, Evaluate, and Integrate Machine Learning Models (part 2)

## Preparatory Reading Material

- [Fairness in Machine Learning is Tricky](https://www.arthur.ai/blog/fairness-in-ml)
- [Fair Warning](https://reallifemag.com/fair-warning/). _For as long as there has been AI research, there have been credible critiques about the risks of AI boosterism_
- [A Survey on Bias and Fairness in Machine Learning](https://arxiv.org/pdf/1908.09635.pdf)

## Lecture Slides

- [Lecture 7 Slides]({{site.baseurl}}/assets/slides/AML4D-L7.pdf) (PDF - 3Mb)

## Lecture Notes

__Work in Progress__

## Additional Material

- [The Machine Learning Canvas]({{site.baseurl}}/assets/material/MachineLearningCanvas.pdf)
- [Tutorial: 21 fairness definitions and their politics](https://www.youtube.com/embed/jIXIuYdnyyk)
- [A Crash Course in Fair NLP for Practitioners](https://www.arthur.ai/blog/crash-course-in-fair-nlp-for-practitioners). Several links to relevant NLP papers
- [Aequitas](http://www.datasciencepublicpolicy.org/our-work/tools-guides/aequitas/). An open source bias audit toolkit for machine learning developers, analysts, and  policymakers to audit machine learning models for discrimination and bias, and make informed and equitable decisions around developing and deploying predictive risk-assessment tools.
